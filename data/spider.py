# -*- coding:utf-8 -*-# data by 58tongcheng# Author zzhimport requestsfrom bs4 import BeautifulSoupimport reclass spider:    def __init__(self, url):        self.url = url        self.page = 1        self.baseUrl = 'http://hu.58.com'        self.list = []    #     处理url，组合rq and bs 返回结果    def __process(self, url, pattrem):        response = requests.get(url)        soup = BeautifulSoup(response.content, 'lxml')        resoult = soup.select(pattrem)        return resoult    # 返回所有区域后缀    def getPage(self):        url = self.url        areas = self.__process(url, 'body > div.mainbox > div.main > div.search_bd > dl.secitem.secitem_fist > dd > a')        # 删除区域中的不限        del areas[0]        return areas        # 递归获取所有租房信息的url  num为0 1 分别为个人房源和经纪人    def getAllPage(self, area, num):        url = self.baseUrl + area+str(num)+'/' + 'pn' + str(self.page)        a = self.__process(url, '#bottom_ad_li > div.pager > a.next')        if len(a) != 0:            self.list.append(a[0]['href'])            self.page += 1            print self.page            self.getAllPage(area,num)        print url    #         获取一个页面的信息内容  0整租 1合租    def getOnePageInfo(self, url):        div = self.__process(url, "ul.listUl > li ")        del div[-1]        list = []        for i in div:            item = {}            if i.select('div.des > h2 > a')[0].text[26:28]==u'整租':                type=0            else:type=1            item['type'] = type            item['size'] = i.select('div.des > p.room')[0].text[-4:-1]            item['money'] = i.select('div.listliright > div.money > b')[0].text            item['address'] = i.select('div.des > p.add > a')[0].text            item['source'] = 0            list.append(item)        return listsp = spider('http://hu.58.com/xinchengqu/chuzu/pn3/')print sp.getAllPage('/xinchengqu/chuzu/',0)# for i in sp.getOnePageList():#     print i